{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(10) * 2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "ax3.plot(np.random.randn(50).cumsum(), 'k--')\n",
    "ax2.scatter(np.arange(30), np.arange(30) + 3 * np.random.randn(30))\n",
    "ax1.hist(np.random.randn(100), bins=20, color='k', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[i, j].hist(np.random.randn(500), bins=50, color='k', alpha=0.5)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.random.randn(30).cumsum(), 'ko--')\n",
    "# same as plt.plot(np.random.randn(30).cumsum(), color='k', linestyle='dashed', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(30).cumsum()\n",
    "plt.plot(data, 'k--', label='Default')\n",
    "plt.plot(data, 'k-', drawstyle='steps-post', label='steps-post')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plotting with pandas\n",
    "#\n",
    "s = pd.Series(np.random.randn(10).cumsum(), index=np.arange(0, 100, 10))\n",
    "print(s)\n",
    "s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.random.randn(10, 4).cumsum(0),\n",
    "    columns=list('ABCD'),\n",
    "    index=np.arange(0, 100, 10)\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# DATA AGGREGATION   /   GROUPS\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'key1': list('aabba'),\n",
    "    'key2': ['one', 'two', 'one', 'two', 'one'],\n",
    "    'data1': np.random.randn(5),\n",
    "    'data2': np.random.randn(5)\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want mean of data1 column using labels from key1\n",
    "grouped = df['data1'].groupby(df['key1'])\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means in relation to key1,key2\n",
    "means = df['data1'].groupby([df['key1'], df['key2']]).mean()\n",
    "means.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df.groupby('key1'):\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key1, key2), group in df.groupby(['key1', 'key2']):\n",
    "    print(key1, key2)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1')['data1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Grouping with stuff\n",
    "#\n",
    "people = pd.DataFrame(\n",
    "    np.random.randn(5, 5),\n",
    "    columns=list('abcde'),\n",
    "    index=['Joe', 'Goncalo', 'Pedro', 'Jim', 'Steve']\n",
    ")\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.iloc[2, [1, 2]] = np.nan\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'a': 'red',\n",
    "    'b': 'red',\n",
    "    'c': 'blue',\n",
    "    'd': 'blue',\n",
    "    'e': 'red',\n",
    "    'f': 'orange'\n",
    "}\n",
    "people.groupby(mapping, axis=1).sum()  # make mapping for every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a series\n",
    "map_series = pd.Series(mapping)\n",
    "people.groupby(map_series, axis=1).count()  # non null observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with functions\n",
    "people.groupby(len).sum()  # length of row names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Data Aggregation\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('key1')\n",
    "grouped['data1'].quantile(0.9)  # 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(lambda arr: arr.max() - arr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "# PROJECTS\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "files_rel_path = os.path.join(os.path.abspath(''), '..', '..', '4-class', 'files')\n",
    "files_path = os.path.realpath(files_rel_path)\n",
    "files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PROJECT 1\n",
    "Service between Bitly and US gov to provide a feed of anonymous data gathered from users who shorten links\n",
    "ending with .gov or .mil  --> service started in 2011, ended in 2017\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(files_path, 'proj1.txt')\n",
    "records = [json.loads(line) for line in open(file)]\n",
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Comparison: couting time zones in pure Python\n",
    "#\n",
    "# time_zones = [record['tz'] for record in records]  # KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zones = [record['tz'] for record in records if 'tz' in record]\n",
    "time_zones[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_counts(data):\n",
    "    counts = defaultdict(int)\n",
    "    for x in data:\n",
    "        counts[x] += 1\n",
    "    return counts\n",
    "\n",
    "tz_counts = get_counts(time_zones)\n",
    "tz_counts['America/New_York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_counts['Europe/Lisbon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10\n",
    "def top_counts(count_dict, n):\n",
    "    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]\n",
    "    value_key_pairs.sort(reverse=True)\n",
    "    return value_key_pairs[:n]\n",
    "\n",
    "top_counts(tz_counts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(time_zones).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # #\n",
    "# Couting time zones with pandas!\n",
    "# # # #\n",
    "df = pd.DataFrame(records)\n",
    "df.info()  # info on the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tz'][:10]   # no need to make if for non existent tzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting, top10\n",
    "tz_counts = df['tz'].value_counts()\n",
    "tz_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "clean_tz = df.tz.fillna('Missing')  # non existent data\n",
    "clean_tz[clean_tz == ''] = 'Unknown'\n",
    "tz_counts = clean_tz.value_counts()\n",
    "tz_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar plot\n",
    "# https://seaborn.pydata.org\n",
    "import seaborn as sns\n",
    "subset = tz_counts[:10]  # top10\n",
    "sns.barplot(x=subset.values, y=subset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check app for url shortening\n",
    "df['a'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series([x.split()[0] for x in df.a.dropna()])\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Decompose top time zones with Windows and non Windows\n",
    "#\n",
    "other_df = df[df.a.notnull()]\n",
    "other_df['os'] = np.where(other_df['a'].str.contains('Windows'), 'Windows', 'Not Windows')\n",
    "other_df['os'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tz_os = other_df.groupby(['tz', 'os'])\n",
    "agg_counts = by_tz_os.size().unstack().fillna(0)  # size ~ value_counts\n",
    "agg_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort agg to check top overall tzs\n",
    "agg_counts.sum(1).argsort()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = agg_counts.sum(1).argsort()  # argsort will skip nan\n",
    "agg_counts.take(indexer[-10:])  # top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange data for plotting\n",
    "count_subset = agg_counts.take(indexer[-10:]).stack()\n",
    "count_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_subset.name = 'total'\n",
    "count_subset = count_subset.reset_index()  # removes multiindex, puts indexrange, create dataframe\n",
    "count_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='total', y='tz', hue='os', data=count_subset)  # hue --> the data we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize group percentages\n",
    "def norm_total(group):\n",
    "    group['normed_total'] = group.total / group.total.sum()  # becomes normalized\n",
    "    return group\n",
    "\n",
    "results = count_subset.groupby('tz').apply(norm_total)\n",
    "sns.barplot(x='normed_total', y='tz', hue='os', data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PROJECT 2\n",
    "US Baby Names 1880-2010, provided by the United States Social Security Administration (SSA)\n",
    "\"\"\"\n",
    "proj2_folder = os.path.join(files_path, 'proj2')\n",
    "names1880 = pd.read_csv(os.path.join(proj2_folder, 'yob1880.txt'), names=['name', 'sex', 'births'])\n",
    "names1880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1880.groupby('sex').births.sum()  # quick stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine in df lots of files\n",
    "years = range(1880, 2011)\n",
    "pieces = []\n",
    "columns = ['name', 'sex', 'births']\n",
    "\n",
    "for year in years:\n",
    "    file = os.path.join(proj2_folder, f'yob{year}.txt')\n",
    "    df_piece = pd.read_csv(file, names=columns)\n",
    "    df_piece['year'] = year  # same number for all elements in this piece\n",
    "    pieces.append(df_piece)\n",
    "\n",
    "# concat\n",
    "names = pd.concat(pieces, ignore_index=True)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate stuff\n",
    "total_births = names.pivot_table('births', index='year', columns='sex', aggfunc=sum)\n",
    "total_births"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_births.plot(title='Total births by sex per year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of babies with given name\n",
    "def add_prop(group):\n",
    "    group['prop'] = group.births / group.births.sum()\n",
    "    return group\n",
    "\n",
    "names = names.groupby(['year', 'sex']).apply(add_prop)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "names.groupby(['year', 'sex']).prop.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subset of data for easier analysis -> top 1000 names for each sex/year combo\n",
    "grouped = names.groupby(['year', 'sex'])\n",
    "top1000 = grouped.apply(lambda group: group.sort_values(by='births', ascending=False)[:1000])\n",
    "top1000.reset_index(inplace=True, drop=True)  # drop resets index without adding column\n",
    "top1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name trends\n",
    "boys = top1000[top1000.sex == 'M']\n",
    "girls = top1000[top1000.sex == 'F']\n",
    "total_births = top1000.pivot_table('births', index='year', columns='name', aggfunc=sum)\n",
    "total_births.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot table for a set of names\n",
    "subset = total_births[['John', 'Harry', 'Jacob', 'Mary', 'Marilyn', 'Elizabeth']]\n",
    "subset.plot(subplots=True, figsize=(12, 10), grid=False, title='Number of births per year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measuring increase in naming diversity -> proportion of babies with name in top1000\n",
    "table = top1000.pivot_table('prop', index='year', columns='sex', aggfunc=sum)\n",
    "table.plot(title='Sum of table1000.prop by year and sex', yticks=np.linspace(0, 1.2, 13), xticks=range(1880, 2020, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering just boys names in 2010\n",
    "df = boys[boys.year == 2010]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cumsum = df.sort_values(by='prop', ascending=False).prop.cumsum()\n",
    "prop_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many of the most popular names it takes to reach 50%\n",
    "prop_cumsum.values.searchsorted(0.5) + 1  # array index start at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for 1900\n",
    "df = boys[boys.year == 1900]\n",
    "in1900 = df.sort_values(by='prop', ascending=False).prop.cumsum()\n",
    "in1900.values.searchsorted(0.5) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for all years, using top1000\n",
    "def get_quantile_count(group):\n",
    "    group = group.sort_values(by='prop', ascending=False)\n",
    "    return group.prop.cumsum().values.searchsorted(0.5) + 1\n",
    "\n",
    "diversity = top1000.groupby(['year', 'sex']).apply(get_quantile_count).unstack('sex')\n",
    "diversity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity.plot(title='Number of popular names in top 50%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "974ac391b4869bf8e598115e047a5b88d1334efda4cfd1faccf8da6f06522048"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
