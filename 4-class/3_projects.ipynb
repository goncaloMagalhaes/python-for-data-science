{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "files_path = os.path.join(os.path.abspath(''), '4-class', 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PROJECT 1\n",
    "Service between Bitly and US gov to provide a feed of anonymous data gathered from users who shorten links\n",
    "ending with .gov or .mil  --> service started in 2011, ended in 2017\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(files_path, 'proj1.txt')\n",
    "records = [json.loads(line) for line in open(file)]\n",
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Comparison: counting time zones in pure Python\n",
    "#\n",
    "# time_zones = [record['tz'] for record in records]  # KeyError because not all data has tz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zones = [record['tz'] for record in records if 'tz' in record]\n",
    "time_zones[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_counts(data):\n",
    "    counts = defaultdict(int)  # non existent accessed keys are set to 0\n",
    "    for x in data:\n",
    "        counts[x] += 1\n",
    "    return counts\n",
    "\n",
    "tz_counts = get_counts(time_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_counts['America/New_York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_counts['Europe/Lisbon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10\n",
    "def top_counts(count_dict, n):\n",
    "    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]\n",
    "    value_key_pairs.sort(reverse=True)\n",
    "    return value_key_pairs[:n]\n",
    "\n",
    "top_counts(tz_counts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(time_zones).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # #\n",
    "# Counting time zones with pandas\n",
    "# # # #\n",
    "df = pd.DataFrame(records)\n",
    "df.info()  # info on the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tz'][:10]  # No need to make if for non existent tzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting, and top10\n",
    "tz_counts = df['tz'].value_counts()\n",
    "tz_counts[:10]  # though notice second place is empty string... As in the pure python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "clean_tz = df.tz.fillna('Missing')  # there are non existent data...\n",
    "clean_tz[clean_tz == ''] = 'Unknown'  # ...and there are empty strings\n",
    "tz_counts = clean_tz.value_counts()\n",
    "tz_counts[:10]  # notice Unknown and Missing creeping into the top10..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do horizontal bar plot\n",
    "# Import seaborn, typical plotting lib for data science, with added features\n",
    "# https://seaborn.pydata.org\n",
    "import seaborn as sns\n",
    "subset = tz_counts[:10]\n",
    "sns.barplot(x=subset.values, y=subset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking app used to perform URL shortening\n",
    "df['a'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series([x.split()[0] for x in df.a.dropna()])  # try fetching \"browser\" info\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Decompose top time zones into Windows and non Windows\n",
    "#\n",
    "other_df = df[df.a.notnull()]\n",
    "other_df['os'] = np.where(other_df['a'].str.contains('Windows'), 'Windows', 'Not Windows')\n",
    "other_df['os'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by tz and os\n",
    "by_tz_os = other_df.groupby(['tz', 'os'])\n",
    "agg_counts = by_tz_os.size().unstack().fillna(0)  # size is group counts, analogous to non group value_counts\n",
    "agg_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort agg to check top overall tzs here. First sort through tz\n",
    "agg_counts.sum(1).argsort()[:10]  # sum through axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve order but show os info\n",
    "indexer = agg_counts.sum(1).argsort()  # argsort will skip nan\n",
    "agg_counts.take(indexer[-10:]) # top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to easily show the biggest values\n",
    "agg_counts.sum(1).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange data for plotting\n",
    "count_subset = agg_counts.take(indexer[-10:]).stack()\n",
    "count_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_subset.name = 'total'\n",
    "count_subset = count_subset.reset_index()  # removes multiindex, puts indexrange, dataframe\n",
    "count_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_subset[:10]  # Dataframe now bigger, since index is not multilevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='total', y='tz', hue='os', data=count_subset)  # hue is, in essence, the data we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's normalize the group percentages\n",
    "def norm_total(group):\n",
    "    group['normed_total'] = group.total / group.total.sum()  # becomes normalized, percentage\n",
    "    return group\n",
    "\n",
    "results = count_subset.groupby('tz').apply(norm_total)\n",
    "sns.barplot(x='normed_total', y='tz', hue='os', data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PROJECT 2\n",
    "US Baby Names 1880-2010, provided by the United States Social Security Administration (SSA)\n",
    "\"\"\"\n",
    "proj2_folder = os.path.join(files_path, 'proj2')\n",
    "names1880 = pd.read_csv(os.path.join(proj2_folder, 'yob1880.txt'), names=['name', 'sex', 'births'])\n",
    "names1880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1880.groupby('sex').births.sum()  # quick stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split into files, combine in df\n",
    "years = range(1880, 2011)\n",
    "pieces = []\n",
    "columns = ['name', 'sex', 'births']\n",
    "\n",
    "for year in years:\n",
    "    file = os.path.join(proj2_folder, f'yob{year}.txt')\n",
    "    df_piece = pd.read_csv(file, names=columns)\n",
    "    df_piece['year'] = year  # tag the year in each piece (each elem of this piece gets this year)\n",
    "    pieces.append(df_piece)\n",
    "\n",
    "# concat\n",
    "names = pd.concat(pieces, ignore_index=True)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate stuff\n",
    "total_births = names.pivot_table('births', index='year', columns='sex', aggfunc=sum)\n",
    "total_births"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_births.plot(title='Total births by sex and year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of babies with given name\n",
    "def add_prop(group):\n",
    "    group['prop'] = group.births / group.births.sum()  # easier than what we did earlier, but same thing\n",
    "    return group\n",
    "\n",
    "names = names.groupby(['year', 'sex']).apply(add_prop)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "names.groupby(['year', 'sex']).prop.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subset of data for easier analysis -> top 1000 names for each sex/year comb\n",
    "\n",
    "grouped = names.groupby(['year', 'sex'])\n",
    "top1000 = grouped.apply(lambda group: group.sort_values(by='births', ascending=False)[:1000])\n",
    "top1000.reset_index(inplace=True, drop=True)  # drop means resets index without adding any column\n",
    "top1000  # dataset is now only ~260.000 instead of ~1.690.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking name trends\n",
    "boys = top1000[top1000.sex == 'M']\n",
    "girls = top1000[top1000.sex == 'F']\n",
    "total_births = top1000.pivot_table('births', index='year', columns='name', aggfunc=sum)\n",
    "total_births.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot table for a set of names\n",
    "subset = total_births[['John', 'Harry', 'Jacob', 'Mary', 'Marilyn', 'Elizabeth']]\n",
    "subset.plot(subplots=True, figsize=(12, 10), grid=False, title='Number of births per year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measuring increase in naming diversity -> proportion of babies with name in top1000\n",
    "table = top1000.pivot_table('prop', index='year', columns='sex', aggfunc=sum)\n",
    "table.plot(title='Sum of table1000.prop by year and sex', yticks=np.linspace(0, 1.2, 13), xticks=range(1880, 2020, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering just boys name in 2010\n",
    "df = boys[boys.year == 2010]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cumsum = df.sort_values(by='prop', ascending=False).prop.cumsum()\n",
    "prop_cumsum[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many of the most popular names it takes to reach 50%\n",
    "prop_cumsum.values.searchsorted(0.5) + 1 # since arrays are 0-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for 1900\n",
    "df = boys[boys.year == 1900]\n",
    "in1900 = df.sort_values(by='prop', ascending=False).prop.cumsum()\n",
    "in1900.values.searchsorted(0.5) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for all years, using top1000\n",
    "def get_quantile_count(group):\n",
    "    group = group.sort_values(by='prop', ascending=False)\n",
    "    return group.prop.cumsum().values.searchsorted(0.5) + 1\n",
    "\n",
    "diversity = top1000.groupby(['year', 'sex']).apply(get_quantile_count).unstack('sex')\n",
    "diversity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity.plot(title='Number of popular names in top 50%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nft certificate? :P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
